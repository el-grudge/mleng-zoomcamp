{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhtPaINnP9zBuz3XAsvT5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/el-grudge/mleng-zoomcamp/blob/main/week_8/homework_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip; unzip -q data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzgupLDcRjDS",
        "outputId": "156ee49f-e7c2-45b0-d634-73647f37199e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-20 00:55:17--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231120T005517Z&X-Amz-Expires=300&X-Amz-Signature=9c92ab3ec8e7e76636cd10290e17e88aaab32df38ec3cdffae070b6c6ef00ec3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-20 00:55:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231120T005517Z&X-Amz-Expires=300&X-Amz-Signature=9c92ab3ec8e7e76636cd10290e17e88aaab32df38ec3cdffae070b6c6ef00ec3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117446836 (112M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 112.01M   302MB/s    in 0.4s    \n",
            "\n",
            "2023-11-20 00:55:18 (302 MB/s) - ‘data.zip’ saved [117446836/117446836]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TvdGd-1QQ8KU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model parameters\n",
        "filter_count = 32\n",
        "filter_size = (3,3)\n",
        "input_shape = (150,150,3)\n",
        "pooling_size = (2,2)"
      ],
      "metadata": {
        "id": "eGIaaLnpRMkQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(filter_count, filter_size, activation='relu', input_shape=input_shape))\n",
        "model.add(layers.MaxPooling2D(pooling_size))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ucoDxgrNRP_H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),\n",
        "             metrics=['acc'])"
      ],
      "metadata": {
        "id": "3M96qlixRQ0P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1\n",
        "\n",
        "Since we have a binary classification problem, what is the best loss function for us?\n",
        "\n",
        "* `mean squared error`\n",
        "* `binary crossentropy`    \n",
        "* `categorical crossentropy`    \n",
        "* `cosine similarity`\n",
        "\n",
        "Answer: `binary crossentropy`"
      ],
      "metadata": {
        "id": "L-G-MXDdRWSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7UfoOFwRSWH",
        "outputId": "cd186258-cda2-4fd8-cf04-e7bdc66a23e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 175232)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11215873 (42.79 MB)\n",
            "Trainable params: 11215873 (42.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2\n",
        "\n",
        "What's the number of parameters in the convolutional layer of our model? You can use the summary method for that.\n",
        "\n",
        "Answer: 11214912"
      ],
      "metadata": {
        "id": "OdCwHvhvRez7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define data generators\n",
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    './data/train',\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxakSS08RgDN",
        "outputId": "3ce30f77-8010-4138-d1a6-61ae468322fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3677 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    './data/test',\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AmUvW3wRsez",
        "outputId": "51a70448-6a37-473c-e57a-1e85f9cf66f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 918 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufnB-awBRv-n",
        "outputId": "0705c60f-31cb-4959-a53f-715e402e7e22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 19s 40ms/step - loss: 0.6721 - acc: 0.5747 - val_loss: 0.7491 - val_acc: 0.5370\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 8s 42ms/step - loss: 0.6171 - acc: 0.6557 - val_loss: 0.5733 - val_acc: 0.7092\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 9s 47ms/step - loss: 0.5704 - acc: 0.7055 - val_loss: 0.5401 - val_acc: 0.7244\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 7s 39ms/step - loss: 0.5308 - acc: 0.7425 - val_loss: 0.5388 - val_acc: 0.7168\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 0.5136 - acc: 0.7520 - val_loss: 0.5214 - val_acc: 0.7669\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 9s 46ms/step - loss: 0.4938 - acc: 0.7773 - val_loss: 0.5348 - val_acc: 0.7298\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 7s 39ms/step - loss: 0.4830 - acc: 0.7813 - val_loss: 0.5340 - val_acc: 0.7353\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 0.4518 - acc: 0.7939 - val_loss: 0.5151 - val_acc: 0.7571\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 8s 42ms/step - loss: 0.4277 - acc: 0.8183 - val_loss: 0.5228 - val_acc: 0.7495\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 7s 39ms/step - loss: 0.3965 - acc: 0.8338 - val_loss: 0.5272 - val_acc: 0.7407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 3\n",
        "\n",
        "What is the median of training accuracy for all the epochs for this model?\n",
        "\n",
        "* 0.20\n",
        "* 0.40\n",
        "* 0.60\n",
        "* 0.80\n",
        "\n",
        "Answer: 0.80"
      ],
      "metadata": {
        "id": "aPNYuWO-STxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.median(history.history['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNj-m5kOSYpb",
        "outputId": "f8934494-6157-4521-ae78-aae43bcaf989"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7646178901195526"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4\n",
        "\n",
        "What is the standard deviation of training loss for all the epochs for this model?\n",
        "\n",
        "* 0.031\n",
        "* 0.061\n",
        "* 0.091\n",
        "* 0.131\n",
        "\n",
        "Answer: 0.091"
      ],
      "metadata": {
        "id": "pMsstWCeS7T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0uwdOLnSvzU",
        "outputId": "fc71f003-4097-41bc-d86f-c446903c1eb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08097588912086935"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest').flow_from_directory(\n",
        "        './data/train',\n",
        "        target_size=(150,150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary',\n",
        "        shuffle=True)"
      ],
      "metadata": {
        "id": "V5gV7-qISuPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e882c1a-1585-407d-be99-0f7b3d92334f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3677 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    './data/test',\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "kRQ2XX_0SXsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c0aa2f-d820-4160-f28b-eaebc783f4c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 918 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m9BO4WQJxGs",
        "outputId": "1f00eaae-5381-4c07-9bcb-61d76f2f98b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 28s 152ms/step - loss: 0.4957 - acc: 0.7786 - val_loss: 0.5398 - val_acc: 0.7538\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 28s 151ms/step - loss: 0.5060 - acc: 0.7648 - val_loss: 0.4722 - val_acc: 0.7778\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 28s 152ms/step - loss: 0.4779 - acc: 0.7830 - val_loss: 0.4854 - val_acc: 0.7767\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 27s 145ms/step - loss: 0.4855 - acc: 0.7696 - val_loss: 0.4903 - val_acc: 0.7734\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 28s 151ms/step - loss: 0.4664 - acc: 0.7803 - val_loss: 0.4729 - val_acc: 0.7712\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 28s 152ms/step - loss: 0.4728 - acc: 0.7800 - val_loss: 0.5039 - val_acc: 0.7745\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 28s 154ms/step - loss: 0.4672 - acc: 0.7841 - val_loss: 0.4972 - val_acc: 0.7680\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 28s 152ms/step - loss: 0.4621 - acc: 0.7944 - val_loss: 0.4798 - val_acc: 0.7745\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 28s 151ms/step - loss: 0.4564 - acc: 0.7939 - val_loss: 0.4786 - val_acc: 0.7832\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 30s 161ms/step - loss: 0.4594 - acc: 0.7914 - val_loss: 0.4774 - val_acc: 0.7800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5\n",
        "\n",
        "Let's train our model for 10 more epochs using the same code as previously.\n",
        "\n",
        "    Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
        "\n",
        "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
        "\n",
        "\n",
        "* 0.18\n",
        "* 0.48\n",
        "* 0.78\n",
        "* 0.108\n",
        "\n",
        "Answer: 0.48"
      ],
      "metadata": {
        "id": "1ArpkQXbIpaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "zP9pbVMdRyDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162e13c5-2608-48d3-8e35-ef00cbb8bdb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4897406905889511"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6\n",
        "\n",
        "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
        "\n",
        "* 0.38\n",
        "* 0.58\n",
        "* 0.78\n",
        "* 0.98\n",
        "\n",
        "Answer: 0.78"
      ],
      "metadata": {
        "id": "e2tCNd2AL-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['val_acc'][5:10])"
      ],
      "metadata": {
        "id": "NSbswnoiRh57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0ee0bf-97f0-4f9c-e26a-8e36aff258a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7760348439216613"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mDKQ2ETtRcJj"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}